import torch
import torchaudio
import pandas as pd
from datasets import Dataset
from transformers import WhisperProcessor, WhisperForConditionalGeneration
from jiwer import cer
import wandb
import os
from dotenv import load_dotenv

load_dotenv()

wandb_api_key = os.getenv("WANDB_API_KEY")
hf_token = os.getenv("HF_TOKEN")

wandb.login(key=wandb_api_key)

# âœ… ì„¤ì •
MODEL_NAME = "SungBeom/whisper-small-ko"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
DATA_PATH = "/workspace/path_and_transcript_validation.csv"   # í‰ê°€ìš© CSV íŒŒì¼ ê²½ë¡œ
SAVE_CSV = True                     # ê²°ê³¼ CSV ì €ì¥ ì—¬ë¶€
OUTPUT_DIR = "output"              # ê²°ê³¼ ì €ì¥ í´ë”

def load_model_and_processor(model_name):
    processor = WhisperProcessor.from_pretrained(model_name, token=hf_token)
    model = WhisperForConditionalGeneration.from_pretrained(model_name, token=hf_token).to(DEVICE)
    model.eval()
    return processor, model

def map_to_pred(batch, processor, model):
    speech_array, sr = torchaudio.load(batch["raw_data"])
    if sr != 16000:
        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)
        speech_array = resampler(speech_array)
    
    input_features = processor(
        speech_array.squeeze(), sampling_rate=16000, return_tensors="pt"
    ).input_features.to(DEVICE)

    with torch.no_grad():
        predicted_ids = model.generate(input_features)
    
    pred = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0].strip().lower()
    batch["prediction"] = pred
    return batch

def run_evaluation():
    # âœ… wandb ì‹¤í—˜ ì´ˆê¸°í™”
    wandb.init(
        project="stt-model-eval",
        name=MODEL_NAME.replace("/", "_"),
        config={
            "model": MODEL_NAME,
            "device": DEVICE,
            "sample_rate": 16000
        }
    )

    # âœ… ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ
    processor, model = load_model_and_processor(MODEL_NAME)
    df = pd.read_csv(DATA_PATH)
    dataset = Dataset.from_pandas(df[["raw_data", "transcript"]])

    # âœ… ì˜ˆì¸¡ ì‹¤í–‰
    result = dataset.map(lambda x: map_to_pred(x, processor, model))

    # âœ… CER ê³„ì‚°
    score = cer(result["transcript"], result["prediction"]) * 100
    print(f"[{MODEL_NAME}] CER: {score:.2f}%")

    # âœ… wandb ë¡œê¹…
    wandb.log({"CER": score})

    # âœ… ê²°ê³¼ CSV ì €ì¥
    if SAVE_CSV:
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        save_path = os.path.join(OUTPUT_DIR, f"{MODEL_NAME.replace('/', '_')}_result.csv")
        result.to_pandas().to_csv(save_path, index=False)
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥: {save_path}")

    # âœ… wandb ì¢…ë£Œ
    wandb.finish()

if __name__ == "__main__":
    run_evaluation()
