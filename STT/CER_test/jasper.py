import torch
import torchaudio
import pandas as pd
from datasets import Dataset
from jiwer import cer
import nemo.collections.asr as nemo_asr
import wandb
import os
from dotenv import load_dotenv

load_dotenv()

wandb_api_key = os.getenv("WANDB_API_KEY")

# âœ… ì„¤ì •
MODEL_NAME = "stt_en_jasper10x5dr"  # ë˜ëŠ” "stt_en_jasper10x5dr"
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
DATA_PATH = "/workspace/path_and_transcript_validation.csv"
SAVE_CSV = True
OUTPUT_DIR = "output"

def load_model(model_name):
    model = nemo_asr.models.EncDecCTCModel.from_pretrained(model_name=model_name)
    model.to(DEVICE)
    model.eval()
    return model

def map_to_pred(batch, model):
    speech_array, sr = torchaudio.load(batch["raw_data"])
    if sr != 16000:
        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)
        speech_array = resampler(speech_array)

    # Hypothesis ê°ì²´ ë°˜í™˜ -> text ì†ì„± ì ‘ê·¼
    transcription = model.transcribe([speech_array.squeeze().numpy()])[0].text.strip().lower()
    batch["prediction"] = transcription
    return batch

def run_evaluation():
    wandb.init(
        project="stt-model-eval-0630",
        name=MODEL_NAME.replace("/", "_"),
        config={
            "model": MODEL_NAME,
            "device": DEVICE,
            "sample_rate": 16000
        }
    )

    # âœ… ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ
    model = load_model(MODEL_NAME)
    df = pd.read_csv(DATA_PATH)
    dataset = Dataset.from_pandas(df[["raw_data", "transcript"]])

    # âœ… ì˜ˆì¸¡ ìˆ˜í–‰
    result = dataset.map(lambda x: map_to_pred(x, model))

    # âœ… CER ê³„ì‚°
    score = cer(result["transcript"], result["prediction"]) * 100
    print(f"[{MODEL_NAME}] CER: {score:.2f}%")

    wandb.log({"CER": score})

    if SAVE_CSV:
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        save_path = os.path.join(OUTPUT_DIR, f"{MODEL_NAME.replace('/', '_')}_result.csv")
        result.to_pandas().to_csv(save_path, index=False)
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥: {save_path}")

    wandb.finish()

if __name__ == "__main__":
    run_evaluation()
