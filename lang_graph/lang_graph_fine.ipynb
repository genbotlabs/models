{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f337c8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version\n",
      "------------------------ -----------\n",
      "aiohappyeyeballs         2.6.1\n",
      "aiohttp                  3.12.13\n",
      "aiosignal                1.4.0\n",
      "annotated-types          0.7.0\n",
      "anyio                    4.9.0\n",
      "appdirs                  1.4.4\n",
      "asttokens                3.0.0\n",
      "attrs                    25.3.0\n",
      "certifi                  2025.6.15\n",
      "charset-normalizer       3.4.2\n",
      "click                    8.2.1\n",
      "colorama                 0.4.6\n",
      "comm                     0.2.2\n",
      "contourpy                1.3.2\n",
      "cycler                   0.12.1\n",
      "dataclasses-json         0.6.7\n",
      "datasets                 3.6.0\n",
      "debugpy                  1.8.11\n",
      "decorator                5.2.1\n",
      "dill                     0.3.8\n",
      "diskcache                5.6.3\n",
      "distro                   1.9.0\n",
      "exceptiongroup           1.3.0\n",
      "executing                2.2.0\n",
      "faiss-cpu                1.11.0\n",
      "fastapi                  0.115.14\n",
      "filelock                 3.18.0\n",
      "fonttools                4.58.5\n",
      "frozenlist               1.7.0\n",
      "fsspec                   2025.3.0\n",
      "graphviz                 0.21\n",
      "greenlet                 3.2.3\n",
      "h11                      0.16.0\n",
      "httpcore                 1.0.9\n",
      "httptools                0.6.4\n",
      "httpx                    0.28.1\n",
      "httpx-sse                0.4.1\n",
      "huggingface-hub          0.33.2\n",
      "idna                     3.10\n",
      "importlib_metadata       8.7.0\n",
      "ipykernel                6.29.5\n",
      "ipython                  9.4.0\n",
      "ipython_pygments_lexers  1.1.1\n",
      "jedi                     0.19.2\n",
      "Jinja2                   3.1.6\n",
      "jiter                    0.10.0\n",
      "joblib                   1.5.1\n",
      "jsonpatch                1.33\n",
      "jsonpointer              3.0.0\n",
      "jupyter_client           8.6.3\n",
      "jupyter_core             5.7.2\n",
      "kiwisolver               1.4.8\n",
      "langchain                0.3.26\n",
      "langchain-community      0.3.27\n",
      "langchain-core           0.3.68\n",
      "langchain-openai         0.3.27\n",
      "langchain-text-splitters 0.3.8\n",
      "langgraph                0.5.1\n",
      "langgraph-checkpoint     2.1.0\n",
      "langgraph-prebuilt       0.5.2\n",
      "langgraph-sdk            0.1.72\n",
      "langsmith                0.4.4\n",
      "MarkupSafe               3.0.2\n",
      "marshmallow              3.26.1\n",
      "matplotlib               3.10.3\n",
      "matplotlib-inline        0.1.7\n",
      "mpmath                   1.3.0\n",
      "multidict                6.6.3\n",
      "multiprocess             0.70.16\n",
      "mypy_extensions          1.1.0\n",
      "nest_asyncio             1.6.0\n",
      "networkx                 3.5\n",
      "numpy                    2.3.1\n",
      "openai                   1.93.0\n",
      "orjson                   3.10.18\n",
      "ormsgpack                1.10.0\n",
      "packaging                24.2\n",
      "pandas                   2.3.1\n",
      "parso                    0.8.4\n",
      "pickleshare              0.7.5\n",
      "pillow                   11.3.0\n",
      "pip                      25.1\n",
      "platformdirs             4.3.8\n",
      "prompt_toolkit           3.0.51\n",
      "propcache                0.3.2\n",
      "psutil                   5.9.0\n",
      "pure_eval                0.2.3\n",
      "pyarrow                  20.0.0\n",
      "pydantic                 2.11.7\n",
      "pydantic_core            2.33.2\n",
      "pydantic-settings        2.10.1\n",
      "Pygments                 2.19.2\n",
      "pyparsing                3.2.3\n",
      "python-dateutil          2.9.0.post0\n",
      "python-dotenv            1.1.1\n",
      "pytz                     2025.2\n",
      "pywin32                  308\n",
      "PyYAML                   6.0.2\n",
      "pyzmq                    26.2.0\n",
      "ragas                    0.2.15\n",
      "regex                    2024.11.6\n",
      "requests                 2.32.4\n",
      "requests-toolbelt        1.0.0\n",
      "safetensors              0.5.3\n",
      "scikit-learn             1.7.0\n",
      "scipy                    1.16.0\n",
      "sentence-transformers    5.0.0\n",
      "setuptools               78.1.1\n",
      "six                      1.17.0\n",
      "sniffio                  1.3.1\n",
      "SQLAlchemy               2.0.41\n",
      "stack_data               0.6.3\n",
      "starlette                0.46.2\n",
      "sympy                    1.14.0\n",
      "tenacity                 9.1.2\n",
      "threadpoolctl            3.6.0\n",
      "tiktoken                 0.9.0\n",
      "tokenizers               0.21.2\n",
      "torch                    2.7.1\n",
      "tornado                  6.5.1\n",
      "tqdm                     4.67.1\n",
      "traitlets                5.14.3\n",
      "transformers             4.53.0\n",
      "typing_extensions        4.14.0\n",
      "typing-inspect           0.9.0\n",
      "typing-inspection        0.4.1\n",
      "tzdata                   2025.2\n",
      "urllib3                  2.5.0\n",
      "uvicorn                  0.35.0\n",
      "watchfiles               1.1.0\n",
      "wcwidth                  0.2.13\n",
      "websockets               15.0.1\n",
      "wheel                    0.45.1\n",
      "xxhash                   3.5.0\n",
      "yarl                     1.20.1\n",
      "zipp                     3.23.0\n",
      "zstandard                0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5466201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Annotated\n",
    "from langchain_core.documents import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import os\n",
    "from langgraph.graph import StateGraph\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "461bf7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Playdata\\AppData\\Local\\Temp\\ipykernel_31608\\1982410193.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large-instruct\")\n",
      "c:\\Users\\Playdata\\anaconda3\\envs\\langgraph_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")  \n",
    "\n",
    "# FAISS ë²¡í„° DB ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-large-instruct\")\n",
    "vectorstore = FAISS.load_local(\"card_QA_faiss_db\", embedding_model,allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa5c997c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from accelerate) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from accelerate) (0.33.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from torch>=2.0.0->accelerate) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\anaconda3\\envs\\langgraph_env\\lib\\site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\n",
      "Downloading accelerate-1.8.1-py3-none-any.whl (365 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.8.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install protobuf\n",
    "# !pip install blobfile protobuf sentencepiece tiktoken\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f90d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x18874f59a30>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated, List, TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import LLMChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "# ðŸ”¹ 1. GraphState ì •ì˜\n",
    "class GraphState(TypedDict):\n",
    "    question: Annotated[str, \"ì§ˆë¬¸\"]\n",
    "    answer: Annotated[str, \"ë‹µë³€\"]\n",
    "    score: Annotated[float, \"ìœ ì‚¬ë„ ì ìˆ˜\"]\n",
    "    retriever_docs: Annotated[List[Document], \"ìœ ì‚¬ë„ ìƒìœ„ë¬¸ì„œ\"]\n",
    "\n",
    "# ðŸ”¹ 2. ëª¨ë¸ ë¡œë“œ ë° íŒŒì´í”„ë¼ì¸ ì„¤ì •\n",
    "MODEL_NAME = \"K-intelligence/Midm-2.0-Mini-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    # device_map=\"auto\",\n",
    "    # low_cpu_mem_usage=True\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.7,\n",
    "    do_sample=True,\n",
    "    top_p=0.9,\n",
    "    # return_full_text=False,  \n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "\n",
    "# ðŸ”¹ 4. ë…¸ë“œ ì •ì˜\n",
    "def retriever_node(state: GraphState) -> GraphState:\n",
    "    docs = vectorstore.similarity_search_with_score(state[\"question\"], k=3)\n",
    "    retrieved_docs = [doc for doc, _ in docs]\n",
    "    score = docs[0][1]\n",
    "    print(\"[retriever_node] ìƒìœ„ ë¬¸ì„œ ì ìˆ˜:\", score)\n",
    "    return GraphState(\n",
    "        question=state[\"question\"],\n",
    "        score=score,\n",
    "        retriever_docs=retrieved_docs,\n",
    "        answer=\"\"  \n",
    "    )\n",
    "\n",
    "def grade_documents_node(state: GraphState) -> GraphState:\n",
    "    return state\n",
    "\n",
    "def llm_answer_node(state: GraphState) -> GraphState:\n",
    "    docs_content = \"\\n---\\n\".join([doc.page_content for doc in state[\"retriever_docs\"]])\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"docs\", \"question\"],\n",
    "        template=\"\"\"\n",
    "    ë¬¸ì„œ:\n",
    "    {docs}\n",
    "\n",
    "    ì§ˆë¬¸:\n",
    "    {question}\n",
    "\n",
    "    ìœ„ ë¬¸ì„œë“¤ì„ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ë‹µë³€í•´ì¤˜.\n",
    "    \"\"\".strip(),\n",
    "    )\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    answer = chain.run(docs=docs_content, question=state[\"question\"])\n",
    "    print(\"[llm_answer_node] ìƒì„±ëœ ë‹µë³€:\", answer)\n",
    "    return GraphState(\n",
    "        question=state[\"question\"],\n",
    "        retriever_docs=state[\"retriever_docs\"],\n",
    "        score=state[\"score\"],\n",
    "        answer=answer\n",
    "    )\n",
    "\n",
    "def query_rewrite_node(state: GraphState) -> GraphState:\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"question\"],\n",
    "        template=\"\"\"\n",
    "        ì›ë³¸ ì§ˆë¬¸: {question}\n",
    "\n",
    "        ìœ„ ì§ˆë¬¸ì˜ í•µì‹¬ì€ ìœ ì§€í•˜ë©´ì„œ, ìœ ì‚¬ ë¬¸ì„œë¥¼ ë” ìž˜ ì°¾ì„ ìˆ˜ ìžˆë„ë¡ ì§ˆë¬¸ì„ ë‹¤ì‹œ ì¨ì¤˜.\n",
    "        ì˜ˆ: \"ë¹„ë²ˆ ë³€ê²½\" â†’ \"ë¹„ë°€ë²ˆí˜¸ ë³€ê²½ ë°©ë²•\"\n",
    "        \"\"\".strip(),\n",
    "    )\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    new_q = chain.run(question=state[\"question\"])\n",
    "    print(\"[query_rewrite_node] ìž¬ìž‘ì„±ëœ ì§ˆë¬¸:\", new_q)\n",
    "    return GraphState(question=new_q)\n",
    "\n",
    "# ðŸ”¹ 5. ì¡°ê±´ ë¶„ê¸° í•¨ìˆ˜\n",
    "def decide_to_generate(state: GraphState) -> str:\n",
    "    # scoreê°€ ë‚®ìœ¼ë©´ ë°”ë¡œ ë‹µë³€, ë†’ìœ¼ë©´ ìž¬ì§ˆë¬¸\n",
    "    return \"llm_answer\" if state[\"score\"] <= 0.23 else \"query_rewrite\"\n",
    "\n",
    "# ðŸ”¹ 6. LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"retriever\", retriever_node)\n",
    "workflow.add_node(\"grade_documents\", grade_documents_node)\n",
    "workflow.add_node(\"llm_answer\", llm_answer_node)\n",
    "workflow.add_node(\"query_rewrite\", query_rewrite_node)\n",
    "\n",
    "workflow.set_entry_point(\"retriever\")\n",
    "workflow.add_edge(\"retriever\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\"llm_answer\": \"llm_answer\", \"query_rewrite\": \"query_rewrite\"},\n",
    ")\n",
    "workflow.add_edge(\"query_rewrite\", \"retriever\")\n",
    "\n",
    "# ì´ì œ `workflow.invoke({\"question\": \"ì›í•˜ëŠ” ì§ˆë¬¸\"})` í˜•íƒœë¡œ ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9bf60c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[retriever_node] ìƒìœ„ ë¬¸ì„œ ì ìˆ˜: 0.26459503\n",
      "[query_rewrite_node] ìž¬ìž‘ì„±ëœ ì§ˆë¬¸:  ë˜ëŠ” \"ë¹„ë°€ë²ˆí˜¸ ë³€ê²½ ì ˆì°¨\"\n",
      "\n",
      "    return:\n",
      "        str: ìƒˆë¡œìš´ ì§ˆë¬¸\n",
      "    \"\"\"\n",
      "    def is_question(query):\n",
      "        return query in QUESTIONS\n",
      "\n",
      "    query = \"ë¹„ë°€ë²ˆí˜¸ ë³€ê²½\"\n",
      "    while True:\n",
      "        if is_question(query):\n",
      "            return query\n",
      "        query = query.replace(\"ë¹„ë²ˆ\", \"ë¹„ë°€ë²ˆí˜¸\")\n",
      "        query = query.replace(\"ë¹„ë²ˆ ë³€ê²½\", \"ë¹„ë°€ë²ˆí˜¸ ë³€ê²½\")\n",
      "        query = query.replace(\"ë³€ê²½\", \"ë³€ê²½ ë°©ë²•\")\n",
      "        query = query.replace(\"ë³€ê²½ ì ˆì°¨\", \"ë³€ê²½ ë°©ë²•\")\n",
      "        query = query.replace(\"ë³€ê²½ ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë³€ê²½\", \"ë³€ê²½ ë°©ë²•\")\n",
      "        query = query.replace(\"ë³€ê²½ ë°©ë²•\", \"ë³€ê²½ ë°©ë²•\")\n",
      "        query = query.replace(\"ë³€ê²½ ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë³€ê²½\", \"ë³€ê²½ ë°©ë²•\")\n",
      "        query = query.replace(\"ë³€ê²½ ë°©ë²•\", \"ë³€ê²½ ë°©ë²•\")\n",
      "        query = query.replace(\"ë³€ê²½\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"\n",
      "[retriever_node] ìƒìœ„ ë¬¸ì„œ ì ìˆ˜: 0.26463008\n",
      "[query_rewrite_node] ìž¬ìž‘ì„±ëœ ì§ˆë¬¸:  ë˜ëŠ” \"ë¹„ë°€ë²ˆí˜¸ ë³€ê²½ ë°©ë²•\"\n",
      "\n",
      "        return:\n",
      "        str: ìƒˆë¡œìš´ ì§ˆë¬¸\n",
      "    \"\"\"\n",
      "    def is_question(query):\n",
      "        return query in QUESTIONS\n",
      "\n",
      "    query = \"ë¹„ë°€ë²ˆí˜¸ ë³€ê²½\"\n",
      "    while True:\n",
      "        if is_question(query):\n",
      "            return query\n",
      "        query = query.replace(\"ë¹„ë²ˆ\", \"ë¹„ë°€ë²ˆí˜¸\")\n",
      "        query = query.replace(\"ë¹„ë²ˆ ë³€ê²½\", \"ë¹„ë°€ë²ˆí˜¸ ë³€ê²½\")\n",
      "        query = query.replace(\"ë³€ê²½\", \"ë³€ê²½ ë°©ë²•\")\n",
      "        query = query.replace(\"ë³€ê²½ ì ˆì°¨\", \"ë³€ê²½ ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë³€ê²½ ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë³€ê²½ ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë³€ê²½ ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "        query = query.replace(\"ë°©ë²•\", \"ë°©ë²•\")\n",
      "\n",
      "[retriever_node] ìƒìœ„ ë¬¸ì„œ ì ìˆ˜: 0.26162404\n",
      "[query_rewrite_node] ìž¬ìž‘ì„±ëœ ì§ˆë¬¸:  ë“±\n",
      "\n",
      "    return query\n",
      "\n",
      "[retriever_node] ìƒìœ„ ë¬¸ì„œ ì ìˆ˜: 0.28589112\n",
      "[query_rewrite_node] ìž¬ìž‘ì„±ëœ ì§ˆë¬¸:  ë“±ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”.\n",
      "\n",
      "# ì˜ˆì‹œ\n",
      "# def get_query(query):\n",
      "#     return query.replace('ë¹„ë²ˆ', 'ë¹„ë°€ë²ˆí˜¸').replace('ë“±', 'ë“±').replace('ë“±')\n",
      "[retriever_node] ìƒìœ„ ë¬¸ì„œ ì ìˆ˜: 0.2567526\n",
      "[query_rewrite_node] ìž¬ìž‘ì„±ëœ ì§ˆë¬¸: \n",
      "[retriever_node] ìƒìœ„ ë¬¸ì„œ ì ìˆ˜: 0.34872836\n",
      "[query_rewrite_node] ìž¬ìž‘ì„±ëœ ì§ˆë¬¸:  \"ë¹„ë²ˆ\" â†’ \"ë¹„ë°€ë²ˆí˜¸\"\n",
      "        \"\"\"\n",
      "        return {\n",
      "            \"question\": self._clean_question(self.original_question),\n",
      "            \"answer\": self._clean_answer(self.original_answer)\n",
      "        }\n",
      "[retriever_node] ìƒìœ„ ë¬¸ì„œ ì ìˆ˜: 0.2655378\n",
      "[query_rewrite_node] ìž¬ìž‘ì„±ëœ ì§ˆë¬¸: \n",
      "[retriever_node] ìƒìœ„ ë¬¸ì„œ ì ìˆ˜: 0.34872836\n",
      "[query_rewrite_node] ìž¬ìž‘ì„±ëœ ì§ˆë¬¸: ìœ¼ë¡œ\n",
      "\n",
      "    # ì˜ˆ\n",
      "    # ì§ˆë¬¸: ë¹„ë²ˆ ë³€ê²½ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”? â†’ ì§ˆë¬¸: ë¹„ë°€ë²ˆí˜¸ ë³€ê²½ ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "    \"\"\"\n",
      "    # ë¹„ë°€ë²ˆí˜¸ ë³€ê²½\n",
      "    def change_password(self):\n",
      "        \"\"\"ë¹„ë°€ë²ˆí˜¸ ë³€ê²½\n",
      "        \"\"\"\n",
      "        if self.password:\n",
      "            self.password = self._form['password'].data\n",
      "            self._form['password'].unset()\n",
      "\n",
      "    def on_password_change(self, event=None):\n",
      "        \"\"\"ë¹„ë°€ë²ˆí˜¸ ë³€ê²½\n",
      "        \"\"\"\n",
      "        event = self.on_password_change\n",
      "        self.change_password()\n",
      "        self.save()\n",
      "\n",
      "    return self.on_password_change\n",
      "\n",
      "# ë¹„ë°€ë²ˆí˜¸ ë³€ê²½\n",
      "def change_password(self):\n",
      "    \"\"\"ë¹„ë°€ë²ˆí˜¸ ë³€ê²½\n",
      "    \"\"\"\n",
      "    if self.password:\n",
      "        self.password = self._form['password'].data\n",
      "        self._form['password'].unset()\n",
      "\n",
      "    return self._form['password'].data\n",
      "[retriever_node] ìƒìœ„ ë¬¸ì„œ ì ìˆ˜: 0.28054124\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mGraphRecursionError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ì‹¤í–‰ \u001b[39;00m\n\u001b[32m      2\u001b[39m app = workflow.compile()\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m response = \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43më¹„ë²ˆ ë³€ê²½\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manswer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mretriever_docs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[ìµœì¢… ë‹µë³€]:\u001b[39m\u001b[33m\"\u001b[39m, response[\u001b[33m\"\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\langgraph_env\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2843\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2840\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2841\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2843\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2844\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2845\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   2847\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2848\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2849\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2850\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2851\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2852\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2853\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2854\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2855\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2856\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\anaconda3\\envs\\langgraph_env\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2558\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2549\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m loop.status == \u001b[33m\"\u001b[39m\u001b[33mout_of_steps\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2550\u001b[39m     msg = create_error_message(\n\u001b[32m   2551\u001b[39m         message=(\n\u001b[32m   2552\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m reached \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2556\u001b[39m         error_code=ErrorCode.GRAPH_RECURSION_LIMIT,\n\u001b[32m   2557\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2558\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[32m   2559\u001b[39m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[32m   2560\u001b[39m run_manager.on_chain_end(loop.output)\n",
      "\u001b[31mGraphRecursionError\u001b[39m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "# ì‹¤í–‰ \n",
    "app = workflow.compile()\n",
    "\n",
    "response = app.invoke({\"question\": \"ë¹„ë²ˆ ë³€ê²½\", \"answer\": \"\", \"score\": 0.0, \"retriever_docs\": []})\n",
    "print(\"\\n[ìµœì¢… ë‹µë³€]:\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8bfa2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
